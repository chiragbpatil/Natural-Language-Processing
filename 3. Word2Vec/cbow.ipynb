{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDjjPQ21KLkq",
        "outputId": "7131c8d7-881d-477d-d0f3-39e346cc266f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "import wget\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import pickle\n",
        "import contractions\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import xml.etree.ElementTree as ET\n",
        "from scipy.spatial.distance import cdist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOvwbMhXKLnR"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN4_PX15KLoD"
      },
      "source": [
        "- will download dataset using datasets library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7VkBmufRKLoE"
      },
      "outputs": [],
      "source": [
        "data_dir = \"Data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SNQ2AR5KLoE"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bWIyReTFKLoF"
      },
      "outputs": [],
      "source": [
        "def preprocess_sent(sentence):\n",
        "    \n",
        "    # expand contractions\n",
        "    # e.g : i'm -> i am\n",
        "    sentence = contractions.fix(sentence)\n",
        "    \n",
        "    #  remove special characters and number\n",
        "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n",
        "    \n",
        "    # remoev multiple spaces with one space\n",
        "    sentence = re.sub(\"\\ +\",\" \",sentence)\n",
        "    \n",
        "    sentence = sentence.strip()\n",
        "    \n",
        "    sentence = sentence.lower() \n",
        "    \n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CQZYz849KLoF"
      },
      "outputs": [],
      "source": [
        "# for training corpus we will use English bible corpus\n",
        "# https://github.com/christos-c/bible-corpus\n",
        "\n",
        "\n",
        "lang = 'English'\n",
        "xml_path = os.path.join(data_dir,f\"{lang}.xml\")\n",
        "txt_path = os.path.join(data_dir,f\"{lang}.txt\")\n",
        "\n",
        "root = ET.fromstring(open(xml_path).read())\n",
        "with open(txt_path, 'w', encoding='utf-8') as out:\n",
        "    for n in root.iter('seg'):\n",
        "        out.write(n.text.strip() + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "X5RbMorJKLoH"
      },
      "outputs": [],
      "source": [
        "preprocessed_sentences = []\n",
        "\n",
        "# will use first 5000 lines\n",
        "with open(txt_path,'r') as f:\n",
        "    lines = f.read().splitlines()[:5000]\n",
        "    for line in lines:\n",
        "        preprocessed_sentences.append(preprocess_sent(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-b2tGswDKLoI",
        "outputId": "0b534eed-fc68-4b74-c08f-705c51bd86bc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'in the beginning god created the heaven and the earth'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_sentences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Zq2mzgKLoJ"
      },
      "source": [
        "# generate data from training model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "plzYCNUHKLoJ"
      },
      "outputs": [],
      "source": [
        "vocab = []\n",
        "for sent in preprocessed_sentences:\n",
        "    vocab.extend(set(sent.split()))\n",
        "vocab = set(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NL1I5yJzKLoL"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HSPk_tPKLoM",
        "outputId": "662f5fae-3859-4062-d03e-591f74864e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_size :  4343\n"
          ]
        }
      ],
      "source": [
        "print(\"vocab_size : \",vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "p79_eD7oKLoM"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for i, word in enumerate(vocab)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tWxY4P1bKLoN"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "window_size = 2 \n",
        "for sent in preprocessed_sentences:\n",
        "    words = sent.split()\n",
        "    \n",
        "    for i in range(window_size, len(words) - window_size):\n",
        "        context = []\n",
        "        target = ''\n",
        "        for j in range(i - window_size,i+window_size+1):\n",
        "            if j ==i:\n",
        "                target = word_to_ix[words[j]]\n",
        "            else:\n",
        "                context.append(word_to_ix[words[j]])\n",
        "        X.append(context)\n",
        "        Y.append(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTEQfN41KLoP",
        "outputId": "04165659-06f9-4e8e-f6bb-4644ed3c5dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4290, 306, 3954, 1065], [306, 3822, 1065, 306], [3822, 3954, 306, 1506], [3954, 1065, 1506, 375], [1065, 306, 375, 306]]\n",
            "[3822, 3954, 1065, 306, 1506]\n"
          ]
        }
      ],
      "source": [
        "print(X[:5])\n",
        "print(Y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dUozHoojKLoQ"
      },
      "outputs": [],
      "source": [
        "X_categorical = tf.keras.utils.to_categorical(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C2yAXWmKLoR",
        "outputId": "fc95aa74-e552-45c4-de61-bf1856e4f854"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(111922, 4, 4343)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_categorical.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXswHX56KLoS"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CkwrwMYPKLoT"
      },
      "outputs": [],
      "source": [
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3,restore_best_weights=True)\n",
        "\n",
        "def get_model(vocab_size,embedding_size,window_size):\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=[2*window_size,vocab_size]),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(embedding_size,name=\"hidden_layer\"),\n",
        "    tf.keras.layers.Dense(vocab_size,name=\"output_layer\",activation='softmax'),\n",
        "    ])\n",
        "    \n",
        "    model.compile('adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Gp61f04LKLoX"
      },
      "outputs": [],
      "source": [
        "model = get_model(vocab_size,128,window_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zld8yq5kKLod",
        "outputId": "8b1ee077-f7fb-449e-8164-2741b784e62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3498/3498 [==============================] - 29s 4ms/step - loss: 4.3931 - accuracy: 0.2875\n",
            "Epoch 2/50\n",
            "3498/3498 [==============================] - 15s 4ms/step - loss: 2.9084 - accuracy: 0.4566\n",
            "Epoch 3/50\n",
            "3498/3498 [==============================] - 15s 4ms/step - loss: 2.3042 - accuracy: 0.5419\n",
            "Epoch 4/50\n",
            "3498/3498 [==============================] - 15s 4ms/step - loss: 1.9028 - accuracy: 0.6011\n",
            "Epoch 5/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 1.6000 - accuracy: 0.6487\n",
            "Epoch 6/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 1.3638 - accuracy: 0.6870\n",
            "Epoch 7/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 1.1766 - accuracy: 0.7206\n",
            "Epoch 8/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 1.0295 - accuracy: 0.7486\n",
            "Epoch 9/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.9154 - accuracy: 0.7686\n",
            "Epoch 10/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.8271 - accuracy: 0.7877\n",
            "Epoch 11/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.7610 - accuracy: 0.8005\n",
            "Epoch 12/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.7080 - accuracy: 0.8114\n",
            "Epoch 13/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.6662 - accuracy: 0.8194\n",
            "Epoch 14/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.6327 - accuracy: 0.8265\n",
            "Epoch 15/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.6054 - accuracy: 0.8321\n",
            "Epoch 16/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.5818 - accuracy: 0.8381\n",
            "Epoch 17/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.5628 - accuracy: 0.8423\n",
            "Epoch 18/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.5456 - accuracy: 0.8458\n",
            "Epoch 19/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.5324 - accuracy: 0.8490\n",
            "Epoch 20/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.5193 - accuracy: 0.8515\n",
            "Epoch 21/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.5092 - accuracy: 0.8544\n",
            "Epoch 22/50\n",
            "3498/3498 [==============================] - 15s 4ms/step - loss: 0.4986 - accuracy: 0.8567\n",
            "Epoch 23/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4902 - accuracy: 0.8596\n",
            "Epoch 24/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4836 - accuracy: 0.8605\n",
            "Epoch 25/50\n",
            "3498/3498 [==============================] - 15s 4ms/step - loss: 0.4751 - accuracy: 0.8625\n",
            "Epoch 26/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4695 - accuracy: 0.8647\n",
            "Epoch 27/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4638 - accuracy: 0.8652\n",
            "Epoch 28/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4575 - accuracy: 0.8667\n",
            "Epoch 29/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4526 - accuracy: 0.8684\n",
            "Epoch 30/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4493 - accuracy: 0.8695\n",
            "Epoch 31/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4448 - accuracy: 0.8701\n",
            "Epoch 32/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4410 - accuracy: 0.8719\n",
            "Epoch 33/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4372 - accuracy: 0.8722\n",
            "Epoch 34/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4340 - accuracy: 0.8731\n",
            "Epoch 35/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4308 - accuracy: 0.8751\n",
            "Epoch 36/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4281 - accuracy: 0.8746\n",
            "Epoch 37/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4256 - accuracy: 0.8746\n",
            "Epoch 38/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4220 - accuracy: 0.8764\n",
            "Epoch 39/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4208 - accuracy: 0.8770\n",
            "Epoch 40/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4181 - accuracy: 0.8768\n",
            "Epoch 41/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4161 - accuracy: 0.8780\n",
            "Epoch 42/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4145 - accuracy: 0.8782\n",
            "Epoch 43/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4120 - accuracy: 0.8788\n",
            "Epoch 44/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4103 - accuracy: 0.8805\n",
            "Epoch 45/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4084 - accuracy: 0.8797\n",
            "Epoch 46/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4071 - accuracy: 0.8800\n",
            "Epoch 47/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4057 - accuracy: 0.8802\n",
            "Epoch 48/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4038 - accuracy: 0.8809\n",
            "Epoch 49/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4024 - accuracy: 0.8816\n",
            "Epoch 50/50\n",
            "3498/3498 [==============================] - 14s 4ms/step - loss: 0.4011 - accuracy: 0.8821\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_categorical,np.array(Y),epochs=50,callbacks=[early_stop_callback],batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvxoYsLtKLoe"
      },
      "source": [
        "# extract word to embeddings for out vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "zp6dSASHVAFf"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"model/embedding_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wCBKIL6Zub1"
      },
      "outputs": [],
      "source": [
        "# model.load_weights(\"model/embedding_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oRSjl_KtKLpW"
      },
      "outputs": [],
      "source": [
        "embeddings = model.get_layer(\"output_layer\").weights[0].numpy().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kZkafvzKLq3",
        "outputId": "470e93a4-363a-4fc3-ef2f-4aa717cc7006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4343, 128)\n"
          ]
        }
      ],
      "source": [
        "print(embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8MU1WirKLq4"
      },
      "source": [
        "- 4343 vocab size and 128 is embedding size\n",
        "- hence for each word we have 128 dimension vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_-mgD-cIKLq4"
      },
      "outputs": [],
      "source": [
        "# build similarity matrix\n",
        "similarities = 1 - cdist(embeddings, embeddings, metric='cosine')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFgSpkqfWjdI",
        "outputId": "0ec00032-a97d-4387-9998-4bf698b9c5f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4343, 4343)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarities.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ynUgtTD6KLq4"
      },
      "outputs": [],
      "source": [
        "word_to_embeddings = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "P0HAxyg3KLrI"
      },
      "outputs": [],
      "source": [
        "for i,emb in enumerate(embeddings):\n",
        "    word_to_embeddings[ix_to_word[i]] = emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "W3q-iq-xKLrc"
      },
      "outputs": [],
      "source": [
        "def get_similarwords(word,k=5):\n",
        "    sim_words = []\n",
        "    if word in vocab:\n",
        "            \n",
        "        index_of_word = word_to_ix[word]\n",
        "\n",
        "        ids = np.argsort(similarities[index_of_word].reshape(1,-1),axis=1)[0]\n",
        "        \n",
        "        for i in ids[-k-1:-1]:\n",
        "            sim_words.append(ix_to_word[i])\n",
        "        \n",
        "        return list(reversed(sim_words))\n",
        "    return \"word is not present in vocab\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzHL745bKLrc",
        "outputId": "aba76c15-3ea6-45fc-a1af-172c8d5148b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lord', 'abram', 'hath', 'merciful', 'israel']"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_similarwords(\"god\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "YPnFodhkOe2j"
      },
      "outputs": [],
      "source": [
        "with open('model/word_to_embeddings.pickle', 'wb') as handle:\n",
        "    pickle.dump(word_to_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('model/ix_to_word.pickle', 'wb') as handle:\n",
        "    pickle.dump(ix_to_word, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('model/word_to_ix.pickle', 'wb') as handle:\n",
        "    pickle.dump(word_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "acwqJhZhKLrq"
      },
      "outputs": [],
      "source": [
        "with open(\"model/similarity_matrix.pickle\",'wb') as handle:\n",
        "    pickle.dump(similarities, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wJfYpWrbcnf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
